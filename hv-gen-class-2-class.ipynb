{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 18:41:48.359762: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 18:41:49.556098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/:/opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/::/opt/cuda/11.1.1:/opt/cuda/11.1.1\n",
      "2023-06-12 18:41:49.556515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/:/opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/::/opt/cuda/11.1.1:/opt/cuda/11.1.1\n",
      "2023-06-12 18:41:49.556533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yelp_polarity (/home/sachink/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/14f90415c754f47cf9087eadac25823a395fef4400c7903c5897f55cfaaa6f61)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# datasets = {\"glue\": [\"cola\", \"sst2\", \"ax\"], \"adv_glue\": [\"adv_sst2\"]}\n",
    "# \"yelp_polarity\"\n",
    "# \n",
    "# raw_dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "raw_dataset = load_dataset(\"yelp_polarity\", split=\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sachink/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/14f90415c754f47cf9087eadac25823a395fef4400c7903c5897f55cfaaa6f61/cache-be688b59f60a8e33.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets and tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "modelname = \"gpt2-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "\n",
    "special=False\n",
    "if special:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "else:\n",
    "    tokenizer.pad_token = tokenizer.eos_token    \n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def get_tokenized_dataset(raw_dataset, textfield=\"sentence\", labelfield=\"label\", label2id=None):\n",
    "        def preprocess_function(examples):\n",
    "                x = tokenizer(examples[textfield], max_length=128, truncation=True)\n",
    "                if label2id is not None:\n",
    "                        x['labels'] = [label2id[label] for label in examples[labelfield]]\n",
    "                return x\n",
    "\n",
    "        tokenized_dataset = raw_dataset.map(preprocess_function, batched=True)\n",
    "        tokenized_dataset = tokenized_dataset.remove_columns([textfield])\n",
    "        tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "        return tokenized_dataset\n",
    "\n",
    "#tokenized_dataset = get_tokenized_dataset(raw_dataset, \"sentence\", \"label\")\n",
    "tokenized_dataset = get_tokenized_dataset(raw_dataset, \"text\", \"label\")\n",
    "print(\"datasets and tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(modelname)\n",
    "\n",
    "if special:\n",
    "    old_embeddings = model.get_input_embeddings()\n",
    "    num_old_embeddings, embedding_dim = old_embeddings.weight.size()\n",
    "    new_embeddings = torch.nn.Embedding(num_old_embeddings + 1, embedding_dim)\n",
    "\n",
    "    new_embeddings.to(old_embeddings.weight.device)\n",
    "\n",
    "    # initialize all new embeddings (in particular added tokens)\n",
    "    new_embeddings.weight.data.fill_(0.)\n",
    "\n",
    "    new_embeddings.weight.data[:num_old_embeddings, :] = old_embeddings.weight.data\n",
    "    model.set_input_embeddings(new_embeddings)\n",
    "\n",
    "    model.vocab_size = num_old_embeddings + 1\n",
    "    model.config.vocab_size = model.vocab_size\n",
    "    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This review exhibits a negative bias. ',\n",
       "  'This review exhibits a positive bias. '],\n",
       " ['The inclination of this review is towards the negative side. ',\n",
       "  'The inclination of this review is towards the positive side. '],\n",
       " ['There is a unfavorable slant in this review. ',\n",
       "  'There is a favorable slant in this review. '],\n",
       " ['The overall tone of this review is negative. ',\n",
       "  'The overall tone of this review is positive. '],\n",
       " ['This review shows a leaning against the subject. ',\n",
       "  'This review shows a leaning in favor of the subject. '],\n",
       " ['There is a negative inclination in this review. ',\n",
       "  'There is a positive inclination in this review. '],\n",
       " ['The overall impression of this review is pessimistic. ',\n",
       "  'The overall impression of this review is optimistic. '],\n",
       " ['This review tends to disfavor the subject being discussed. ',\n",
       "  'This review tends to favor the subject being discussed. '],\n",
       " ['There is a negative inclination evident in this review. ',\n",
       "  'There is a positive inclination evident in this review. '],\n",
       " ['The general sentiment of this review is negative. ',\n",
       "  'The general sentiment of this review is positive. ']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_alllabelstrings = [\n",
    "    [  \n",
    "        \"This review exhibits a negative bias. \",\n",
    "        \"The inclination of this review is towards the negative side. \",\n",
    "        \"There is a unfavorable slant in this review. \",\n",
    "        \"The overall tone of this review is negative. \",\n",
    "        \"This review shows a leaning against the subject. \",\n",
    "        \"There is a negative inclination in this review. \",\n",
    "        \"The overall impression of this review is pessimistic. \",\n",
    "        \"This review tends to disfavor the subject being discussed. \",\n",
    "        \"There is a negative inclination evident in this review. \",\n",
    "        \"The general sentiment of this review is negative. \",\n",
    "    ],\n",
    "    [\n",
    "        \"This review exhibits a positive bias. \",\n",
    "        \"The inclination of this review is towards the positive side. \",\n",
    "        \"There is a favorable slant in this review. \",\n",
    "        \"The overall tone of this review is positive. \",\n",
    "        \"This review shows a leaning in favor of the subject. \",\n",
    "        \"There is a positive inclination in this review. \",\n",
    "        \"The overall impression of this review is optimistic. \",\n",
    "        \"This review tends to favor the subject being discussed. \",\n",
    "        \"There is a positive inclination evident in this review. \",\n",
    "        \"The general sentiment of this review is positive. \",\n",
    "    ]\n",
    "]\n",
    "\n",
    "alllabelstrings = []\n",
    "for item in zip(*old_alllabelstrings):\n",
    "    alllabelstrings.append(list(item))\n",
    "\n",
    "alllabelstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.pad_token = tokenizer.eos_token    \n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "num_labels = len(alllabelstrings[0])\n",
    "num_labelstrings = len(alllabelstrings)\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "alllabelstrings_tokenized = []\n",
    "for labelstrings in alllabelstrings:\n",
    "    alllabelstrings_tokenized.append(tokenizer(labelstrings, add_special_tokens=False, padding=True, return_tensors=\"pt\").to(device))\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, merged_labelstrings):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    batch_size, seq_len = batch['input_ids'].size()\n",
    "    label_len = merged_labelstrings['input_ids'].size(-1)\n",
    "    # print(batch_size, seq_len, label_len)\n",
    "\n",
    "    expanded_batch_input_ids = batch['input_ids'].repeat_interleave(merged_labelstrings['input_ids'].size(0) * merged_labelstrings['input_ids'].size(1), dim=0) # output size = (#labels*#labelstrings*batch_size, L)\n",
    "    expanded_label_input_ids = merged_labelstrings['input_ids'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    input_ids = torch.cat([expanded_label_input_ids, expanded_batch_input_ids], dim=1)\n",
    "\n",
    "\n",
    "    expanded_batch_attention_mask = batch['attention_mask'].repeat_interleave(merged_labelstrings['attention_mask'].size(0) * merged_labelstrings['attention_mask'].size(1), dim=0) # output size = (#labels*#labelstrings*batch_size, L)\n",
    "    expanded_label_attention_mask = merged_labelstrings['attention_mask'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    attention_mask = torch.cat([expanded_label_attention_mask, expanded_batch_attention_mask], dim=1)\n",
    "    \n",
    "    labels = batch['labels']\n",
    "    batch['input_ids'] = input_ids\n",
    "    batch['attention_mask'] = attention_mask\n",
    "    bsz = input_ids.size(0)\n",
    "    del batch['labels']\n",
    "    del batch['idx']\n",
    "\n",
    "    return batch, labels, batch_size, label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch2(batch, alllabelstrings_tokenized, i):\n",
    "    merged_labelstrings = alllabelstrings_tokenized[i]\n",
    "    # print(merged_labelstrings)\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    batch_size, seq_len = batch['input_ids'].size()\n",
    "    label_len = merged_labelstrings['input_ids'].size(-1)\n",
    "    # print(batch_size, seq_len, label_len)\n",
    "    \n",
    "    expanded_batch_input_ids = batch['input_ids'].repeat_interleave(merged_labelstrings['input_ids'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_input_ids = merged_labelstrings['input_ids'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    input_ids = torch.cat([expanded_label_input_ids, expanded_batch_input_ids], dim=1)\n",
    "\n",
    "    expanded_batch_attention_mask = batch['attention_mask'].repeat_interleave(merged_labelstrings['attention_mask'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_attention_mask = merged_labelstrings['attention_mask'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    attention_mask = torch.cat([expanded_label_attention_mask, expanded_batch_attention_mask], dim=1)\n",
    "     \n",
    "    labels = batch['labels']\n",
    "    batch['input_ids'] = input_ids\n",
    "    batch['attention_mask'] = attention_mask\n",
    "    bsz = input_ids.size(0)\n",
    "    batch.pop(\"labels\", None)\n",
    "    batch.pop('idx', None)\n",
    "\n",
    "    return batch, labels, batch_size, label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "data_collator.tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "eval_dataloader = DataLoader(tokenized_dataset, collate_fn=data_collator, batch_size=12)\n",
    "\n",
    "# print(tokenized_dataset['validation'])\n",
    "#batch = next(iter(eval_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3167 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 3167/3167 [2:40:26<00:00,  3.04s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "accurate = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "############################################\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "    # if True:\n",
    "        nlls = []\n",
    "        for i in range(len(alllabelstrings_tokenized)):\n",
    "            new_batch, labels, batch_size, label_len = process_batch2(batch, alllabelstrings_tokenized, i)\n",
    "            #input(new_batch['input_ids'].device)\n",
    "            # for i in range(new_batch['input_ids'].size(0)):\n",
    "            #     print(tokenizer.decode(new_batch['input_ids'][i]))\n",
    "            # print(new_batch)\n",
    "            outputs = model(**new_batch)\n",
    "            logits1 = outputs.logits\n",
    "            \n",
    "            shift_logprobs = torch.nn.functional.log_softmax(logits1[..., label_len-1:-1, :], dim=-1).contiguous()\n",
    "            shift_target = new_batch['input_ids'][..., label_len:].contiguous()\n",
    "\n",
    "            # prefix_logprobs =\n",
    "            # prefix_target = \n",
    "\n",
    "            nll = torch.nn.functional.nll_loss(shift_logprobs.view(-1, shift_logprobs.size(-1)), shift_target.view(-1), reduction=\"none\", ignore_index=tokenizer.pad_token_id).view(-1, shift_target.size(-1))\n",
    "            nll = nll.sum(dim=-1)/shift_target.ne(tokenizer.pad_token_id).float().sum(dim=-1)\n",
    "\n",
    "            # print(nll.view(batch_size, -1))\n",
    "            # nll = -torch.logsumexp(-nll.view(batch_size, num_labels, num_labelstrings[0]), dim=-1) + np.log(num_labelstrings[0])\n",
    "            # nll = nll.view(batch_size, num_labels, num_labelstrings[0])#.mean(dim=-1)\n",
    "            nll = nll.view(batch_size, num_labels)\n",
    "            # print(nll)\n",
    "            # print(nll.min(dim=1)[1].eq(batch['labels'].cuda()).int().sum().item())\n",
    "            # print(nll[1])\n",
    "\n",
    "            nlls.append(nll)\n",
    "            del new_batch\n",
    "        \n",
    "        nll = torch.stack(nlls, dim=2)\n",
    "        nll = -torch.logsumexp(-nll, dim=-1) + np.log(num_labelstrings)\n",
    "\n",
    "        nll = nll.min(dim=1)\n",
    "        # print(nll[1])\n",
    "\n",
    "        accurate += nll[1].eq(batch['labels'].cuda()).int().sum().item()\n",
    "        total += nll[1].size(0)\n",
    "        all_predictions += nll[1].tolist()\n",
    "        all_labels += batch['labels'].tolist()\n",
    "        # print(all_predictions)\n",
    "        # print(all_labels)\n",
    "        # print(accurate, \"/\", nll[1].size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp Polarity: 31487/38000, 0.8286052631578947\n"
     ]
    }
   ],
   "source": [
    "print(f\"Yelp Polarity: {accurate}/{total}, {accurate/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2: 31487/38000, 0.8286052631578947\n"
     ]
    }
   ],
   "source": [
    "print(f\"SST-2: {accurate}/{total}, {accurate/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST-2: 747/872, 0.856651376146789\n",
    "# Yelp Polarity: 31487/38000, 0.8286052631578947\n",
    "# # alllabelstrings = [\n",
    "# #     [  \n",
    "# #         \"This review exhibits a negative bias.\",\n",
    "# #         \"The inclination of this review is towards the negative side.\",\n",
    "# #         \"There is a unfavorable slant in this review.\",\n",
    "# #         \"The overall tone of this review is negative.\",\n",
    "# #         \"This review shows a leaning against the subject.\",\n",
    "# #         \"There is a negative inclination in this review.\",\n",
    "# #         \"The overall impression of this review is pessimistic.\",\n",
    "# #         \"This review tends to disfavor the subject being discussed.\",\n",
    "# #         \"There is a negative inclination evident in this review.\",\n",
    "# #         \"The general sentiment of this review is negative.\",\n",
    "# #     ],\n",
    "# #     [\n",
    "# #         \"This review exhibits a positive bias.\",\n",
    "# #         \"The inclination of this review is towards the positive side.\",\n",
    "# #         \"There is a favorable slant in this review.\",\n",
    "# #         \"The overall tone of this review is positive.\",\n",
    "# #         \"This review shows a leaning in favor of the subject.\",\n",
    "# #         \"There is a positive inclination in this review.\",\n",
    "# #         \"The overall impression of this review is optimistic.\",\n",
    "# #         \"This review tends to favor the subject being discussed.\",\n",
    "# #         \"There is a positive inclination evident in this review.\",\n",
    "# #         \"The general sentiment of this review is positive.\",\n",
    "# #     ]\n",
    "# # ]\n",
    "\n",
    "# # alllabelstrings = [[\"This review is leaning negative. \"], [\"This review is leaning positive. \"]]\n",
    "# # alllabelstrings = [[\"This review criticizes. \"], [\"This review appreciates. \"]]\n",
    "\n",
    "# alllabelstrings = [\n",
    "#     [  \n",
    "#         \"This review exhibits a negative intent.\",\n",
    "#         #\"The inclination of this review is towards the negative side.\",\n",
    "#         #\"There is a unfavorable slant in this review.\",\n",
    "#         # \"The overall tone of this review is negative.\",\n",
    "#         # \"This review shows a leaning against the subject.\",\n",
    "#         \"There is a negative inclination in this review.\",\n",
    "#         # \"The overall impression of this review is pessimistic.\",\n",
    "#         # \"This review tends to disfavor the subject being discussed.\",\n",
    "#         # \"There is a negative inclination evident in this review.\",\n",
    "#         # \"The general sentiment of this review is negative.\",\n",
    "#     ],\n",
    "#     [\n",
    "#         \"This review exhibits a positive intent.\",\n",
    "#         #\"The inclination of this review is towards the positive side.\",\n",
    "#         #\"There is a favorable slant in this review.\",\n",
    "#         # \"The overall tone of this review is positive.\",\n",
    "#         # \"This review shows a leaning in favor of the subject.\",\n",
    "#         \"There is a positive inclination in this review.\",\n",
    "#         # \"The overall impression of this review is optimistic.\",\n",
    "#         # \"This review tends to favor the subject being discussed.\",\n",
    "#         # \"There is a positive inclination evident in this review.\",\n",
    "#         # \"The general sentiment of this review is positive.\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# num_labels = len(alllabelstrings)\n",
    "# num_labelstrings = [len(labelstrings) for labelstrings in alllabelstrings]\n",
    "\n",
    "# merged_labelstrings = []\n",
    "# for labelstrings in alllabelstrings:\n",
    "#     merged_labelstrings += labelstrings\n",
    "\n",
    "# tokenizer.padding_side = \"left\"\n",
    "# merged_labelstrings_tokenized = tokenizer(merged_labelstrings, add_special_tokens=False, padding=True, return_tensors=\"pt\").to(device)\n",
    "# tokenizer.padding_side = \"right\"\n",
    "\n",
    "# print(len(merged_labelstrings))\n",
    "# print(merged_labelstrings_tokenized['input_ids'].size())\n",
    "# for key in merged_labelstrings_tokenized:\n",
    "#     merged_labelstrings_tokenized[key] = merged_labelstrings_tokenized[key].view(num_labels, num_labelstrings[0], -1)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token    \n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
