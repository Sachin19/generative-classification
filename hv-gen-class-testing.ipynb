{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-12 21:50:18.377432: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-12 21:50:19.587921: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/:/opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/::/opt/cuda/11.1.1:/opt/cuda/11.1.1\n",
      "2023-06-12 21:50:19.588199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/:/opt/cudnn/cuda-9.1/7.1/cuda/lib64:/opt/cuda/11.1.1/extras/CUPTI/lib64/::/opt/cuda/11.1.1:/opt/cuda/11.1.1\n",
      "2023-06-12 21:50:19.588207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/sachink/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "raw_dataset = load_dataset(\"sst2\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from transformers.tokenization_utils_base import PreTrainedTokenizerBase\n",
    "\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "\n",
    "from transformers.utils import PaddingStrategy\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorForGenerativeClassification:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "\n",
    "    Args:\n",
    "        tokenizer ([`PreTrainedTokenizer`] or [`PreTrainedTokenizerFast`]):\n",
    "            The tokenizer used for encoding the data.\n",
    "        padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "\n",
    "            - `True` or `'longest'` (default): Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence is provided).\n",
    "            - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
    "              acceptable input length for the model if that argument is not provided.\n",
    "            - `False` or `'do_not_pad'`: No padding (i.e., can output a batch with sequences of different lengths).\n",
    "        max_length (`int`, *optional*):\n",
    "            Maximum length of the returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (`int`, *optional*):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "        return_tensors (`str`):\n",
    "            The type of Tensor to return. Allowable values are \"np\", \"pt\" and \"tf\".\n",
    "    \"\"\"\n",
    "\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    label_features = None\n",
    "    padding: Union[bool, str, PaddingStrategy] = True\n",
    "    max_length: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "\n",
    "    def __call__(self, features):\n",
    "        new_features = {}\n",
    "        for key in features:\n",
    "            if key not in ['input_ids', 'attention_mask']:\n",
    "                pass\n",
    "        \n",
    "\n",
    "        batch = self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=self.return_tensors,\n",
    "        )\n",
    "\n",
    "\n",
    "        if \"label\" in batch:\n",
    "            batch[\"labels\"] = batch[\"label\"]\n",
    "            del batch[\"label\"]\n",
    "        if \"label_ids\" in batch:\n",
    "            batch[\"labels\"] = batch[\"label_ids\"]\n",
    "            del batch[\"label_ids\"]\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/sachink/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5/cache-5ef0f9d7ba4525a8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets and tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "modelname = \"gpt2-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token    \n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "def get_tokenized_dataset(raw_dataset, textfield=\"sentence\", labelfield=\"label\", label2id=None):\n",
    "        def preprocess_function(examples):\n",
    "                x = tokenizer(examples[textfield], max_length=200, truncation=True)\n",
    "                if label2id is not None:\n",
    "                        x['labels'] = [label2id[label] for label in examples[labelfield]]\n",
    "                return x\n",
    "\n",
    "        tokenized_dataset = raw_dataset.map(preprocess_function, batched=True)\n",
    "        tokenized_dataset = tokenized_dataset.remove_columns([textfield])\n",
    "        tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "        return tokenized_dataset\n",
    "\n",
    "tokenized_dataset = get_tokenized_dataset(raw_dataset, \"sentence\", \"label\")\n",
    "# tokenized_dataset = get_tokenized_dataset(raw_dataset, \"text\", \"label\")\n",
    "print(\"datasets and tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': tensor([0, 1, 2]),\n",
       " 'label': tensor([1, 0, 1]),\n",
       " 'input_ids': [tensor([  270,   705,    82,   257, 23332,   290,  1690, 13891,  7002,   764,\n",
       "            220]),\n",
       "  tensor([  403,  2704,  8589,  4420, 30942,   290, 12111,   220]),\n",
       "  tensor([47205,   514,   284,  2911,   326,   299, 16617,   318, 24357,   284,\n",
       "          21030,   257,  1688,  3451,   355,   257,  5068,  1865, 47602, 26479,\n",
       "            764,   220])],\n",
       " 'attention_mask': [tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1]),\n",
       "  tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])]}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(modelname)    \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllabelstrings = [\n",
    "    [  \n",
    "        \"This review exhibits a negative bias. \",\n",
    "        \"The inclination of this review is towards the negative side. \",\n",
    "        \"There is a unfavorable slant in this review. \",\n",
    "        \"The overall tone of this review is negative. \",\n",
    "        \"This review shows a leaning against the subject. \",\n",
    "        \"There is a negative inclination in this review. \",\n",
    "        \"The overall impression of this review is pessimistic. \",\n",
    "        \"This review tends to disfavor the subject being discussed. \",\n",
    "        \"There is a negative inclination evident in this review. \",\n",
    "        \"The general sentiment of this review is negative. \",\n",
    "    ],\n",
    "    [\n",
    "        \"This review exhibits a positive bias. \",\n",
    "        \"The inclination of this review is towards the positive side. \",\n",
    "        \"There is a favorable slant in this review. \",\n",
    "        \"The overall tone of this review is positive. \",\n",
    "        \"This review shows a leaning in favor of the subject. \",\n",
    "        \"There is a positive inclination in this review. \",\n",
    "        \"The overall impression of this review is optimistic. \",\n",
    "        \"This review tends to favor the subject being discussed. \",\n",
    "        \"There is a positive inclination evident in this review. \",\n",
    "        \"The general sentiment of this review is positive. \",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'input_ids': tensor([[ 1212,  2423, 27508,   257,  4633, 10690,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464, 36793,   286,   428,  2423,   318,  3371,   262,  4633,  1735,\n",
       "              13,   220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257, 38206,  1017,   415,   287,   428,  2423,    13,\n",
       "             220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 464, 4045, 8216,  286,  428, 2423,  318, 4633,   13,  220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1212,  2423,  2523,   257, 21804,  1028,   262,  2426,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257,  4633, 36793,   287,   428,  2423,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464,  4045, 10647,   286,   428,  2423,   318, 46392,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1212,  2423, 12444,   284,   595,    69,  5570,   262,  2426,   852,\n",
       "            6693,    13,   220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257,  4633, 36793, 10678,   287,   428,  2423,    13,\n",
       "             220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464,  2276, 15598,   286,   428,  2423,   318,  4633,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}],\n",
       " [{'input_ids': tensor([[ 1212,  2423, 27508,   257,  3967, 10690,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464, 36793,   286,   428,  2423,   318,  3371,   262,  3967,  1735,\n",
       "              13,   220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257, 17070,  1017,   415,   287,   428,  2423,    13,\n",
       "             220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 464, 4045, 8216,  286,  428, 2423,  318, 3967,   13,  220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1212,  2423,  2523,   257, 21804,   287,  2661,   286,   262,  2426,\n",
       "              13,   220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257,  3967, 36793,   287,   428,  2423,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464,  4045, 10647,   286,   428,  2423,   318, 16915,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1212,  2423, 12444,   284,  2661,   262,  2426,   852,  6693,    13,\n",
       "             220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[ 1858,   318,   257,  3967, 36793, 10678,   287,   428,  2423,    13,\n",
       "             220]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')},\n",
       "  {'input_ids': tensor([[  464,  2276, 15598,   286,   428,  2423,   318,  3967,    13,   220]],\n",
       "         device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer.pad_token = tokenizer.eos_token    \n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "num_labels = len(alllabelstrings)\n",
    "num_labelstrings = len(alllabelstrings[0])\n",
    "\n",
    "alllabelstrings_tokenized = []\n",
    "for labelstrings in alllabelstrings:\n",
    "    labelstrings_tokenized = []\n",
    "    for labelstring in labelstrings:\n",
    "        labelstrings_tokenized.append(tokenizer(labelstring, add_special_tokens=False, padding=False, return_tensors=\"pt\").to(device))\n",
    "    alllabelstrings_tokenized.append(labelstrings_tokenized)\n",
    "\n",
    "\n",
    "alllabelstrings_tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[64], [64, 275], [64, 275, 269]], 'attention_mask': [[1], [1, 1], [1, 1, 1]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [\"a\", \"a b\", \"a b c\"]\n",
    "tokenizer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch, alllabelstrings_tokenized, i, j):\n",
    "    labelstring_tokenized = alllabelstrings_tokenized[i][j]\n",
    "    #print(batch.keys())\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    batch_size, seq_len = batch['input_ids'].size()\n",
    "    label_len = labelstring_tokenized['input_ids'].size(-1)\n",
    "    # print(batch_size, seq_len, label_len)\n",
    "    \n",
    "    expanded_batch_input_ids = batch['input_ids'].repeat_interleave(labelstring_tokenized['input_ids'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_input_ids = labelstring_tokenized['input_ids'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    input_ids = torch.cat([expanded_label_input_ids, expanded_batch_input_ids], dim=1)\n",
    "\n",
    "    expanded_batch_attention_mask = batch['attention_mask'].repeat_interleave(labelstring_tokenized['attention_mask'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_attention_mask = labelstring_tokenized['attention_mask'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    attention_mask = torch.cat([expanded_label_attention_mask, expanded_batch_attention_mask], dim=1)\n",
    "    \n",
    "    label_mask = torch.ones_like(attention_mask)[:label_len] = 0.\n",
    "    labels = batch['labels']\n",
    "    batch['input_ids'] = input_ids\n",
    "    batch['attention_mask'] = attention_mask\n",
    "    bsz = input_ids.size(0)\n",
    "    batch.pop(\"labels\", None)\n",
    "    batch.pop('idx', None)\n",
    "\n",
    "    return batch, labels, batch_size, label_len, label_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch2(batch, alllabelstrings_tokenized, i):\n",
    "    merged_labelstrings = alllabelstrings_tokenized[i]\n",
    "    # print(merged_labelstrings)\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    batch_size, seq_len = batch['input_ids'].size()\n",
    "    label_len = merged_labelstrings['input_ids'].size(-1)\n",
    "    # print(batch_size, seq_len, label_len)\n",
    "    \n",
    "    expanded_batch_input_ids = batch['input_ids'].repeat_interleave(merged_labelstrings['input_ids'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_input_ids = merged_labelstrings['input_ids'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    input_ids = torch.cat([expanded_label_input_ids, expanded_batch_input_ids], dim=1)\n",
    "\n",
    "    expanded_batch_attention_mask = batch['attention_mask'].repeat_interleave(merged_labelstrings['attention_mask'].size(0), dim=0) # output size = (#labels*batch_size, L)\n",
    "    expanded_label_attention_mask = merged_labelstrings['attention_mask'].view(1, -1, label_len).expand(batch_size, -1, -1).contiguous().view(-1, label_len)\n",
    "    attention_mask = torch.cat([expanded_label_attention_mask, expanded_batch_attention_mask], dim=1)\n",
    "     \n",
    "    labels = batch['labels']\n",
    "    batch['input_ids'] = input_ids\n",
    "    batch['attention_mask'] = attention_mask\n",
    "    bsz = input_ids.size(0)\n",
    "    batch.pop(\"labels\", None)\n",
    "    batch.pop('idx', None)\n",
    "\n",
    "    return batch, labels, batch_size, label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'idx': tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11]), 'input_ids': tensor([[  270,   705,    82,   257, 23332,   290,  1690, 13891,  7002,   764,\n",
       "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [  403,  2704,  8589,  4420, 30942,   290, 12111,   220, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [47205,   514,   284,  2911,   326,   299, 16617,   318, 24357,   284,\n",
       "         21030,   257,  1688,  3451,   355,   257,  5068,  1865, 47602, 26479,\n",
       "           764,   220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [ 1169,  7205,   837, 24138,   837,  2647,   837, 13483, 45501,   290,\n",
       "          2128,   389,   477, 34328,  1813,   262,  3227,   705,    82, 38132,\n",
       "           567,  1957,   274,   764,   220, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [  270,   705,    82,  3105,  1377,   845,   837,   845,  3105,   764,\n",
       "           220, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [16670, 49699,   351, 14733,   290,   257,  1178, 39980,  4135, 18105,\n",
       "           837,   262,  2646,   318,   257, 23056,   306,  2726,   804,   379,\n",
       "          1862,  1466,   764,   220, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [   64,  3360, 32460,  2646,   764,   220, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [  273,  1804,   938,   614,   705,    82,  5704,   351,   534,   409,\n",
       "            12, 22095,   764,   220, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [ 5832,   466,   299,   470,   423,   284,   760,   546,  2647,   284,\n",
       "          9144,   262,  2646,   705,    82,  2562,  5146, 13516,   286, 10997,\n",
       "           290, 19661,   764,   220, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [  259,  3446,  9919,  2431,   837,   749,   286,   543,  3804,   355,\n",
       "          6364,   355,   611,  1312,   705,    67,   587,  5586, 12105,   319,\n",
       "           281, 45329, 29680,   837, 10451,  6885, 30895,   422, 37276,   284,\n",
       "         13665,  2584,   284, 10517, 26876,   764,   220, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [ 1169, 46814,  2890, 13289,   286,   262,  5983,  1394,   262,  2646,\n",
       "         22804,   290,  1394,   262,  5386, 40112,  1513,   764,   220, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "         50256, 50256, 50256],\n",
       "        [  270,  2753,   257,  6283,  1611,   286, 37296,  1272,   284,  7030,\n",
       "           262, 18054,   286,   686,  4835,   329,  1706,   837,   281,   710,\n",
       "           285,   451,    64,   837,   304,  1018,  1734, 35783,   837,   290,\n",
       "           842,  1292,    67, 11555, 30686,  1559,   477,   287,   262,   976,\n",
       "          3807,   764,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0])}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\")\n",
    "data_collator.tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "eval_dataloader = DataLoader(tokenized_dataset, collate_fn=data_collator, batch_size=12)\n",
    "\n",
    "# print(tokenized_dataset['validation'])\n",
    "batch = next(iter(eval_dataloader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n",
      "dict_keys(['idx', 'input_ids', 'attention_mask', 'labels'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_78218/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2094663292.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">43</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 8&gt;</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_78218/2094663292.py'</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">RuntimeError: </span>The size of tensor a <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> must match the size of tensor b <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">)</span> at non-singleton dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_78218/\u001b[0m\u001b[1;33m2094663292.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92m<cell line: 8>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_78218/2094663292.py'\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mRuntimeError: \u001b[0mThe size of tensor a \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m must match the size of tensor b \u001b[1m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1m)\u001b[0m at non-singleton dimension \u001b[1;36m1\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "accurate = 0\n",
    "total = 0\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "############################################\n",
    "with torch.no_grad():\n",
    "    # for batch in tqdm(eval_dataloader):\n",
    "    if True:\n",
    "        nlls = []\n",
    "        for i in range(len(alllabelstrings_tokenized)):\n",
    "            perlabel_nlls = []\n",
    "            for j in range(len(alllabelstrings_tokenized[i])):\n",
    "                new_batch, labels, batch_size, label_len, label_mask = process_batch(batch, alllabelstrings_tokenized, i, j)\n",
    "                \n",
    "                outputs = model(**new_batch)\n",
    "                logits1 = outputs.logits\n",
    "                \n",
    "                shift_logprobs = torch.nn.functional.log_softmax(logits1[..., label_len-1:-1, :], dim=-1).contiguous()\n",
    "                shift_target = new_batch['input_ids'][..., label_len:].contiguous()\n",
    "\n",
    "                nll = torch.nn.functional.nll_loss(shift_logprobs.view(-1, shift_logprobs.size(-1)), shift_target.view(-1), reduction=\"none\", ignore_index=tokenizer.pad_token_id).view(-1, shift_target.size(-1))\n",
    "                nll = nll.sum(dim=-1)/shift_target.ne(tokenizer.pad_token_id).float().sum(dim=-1)\n",
    "\n",
    "                nll = nll.view(batch_size, 1)\n",
    "                # print(nll)\n",
    "                # print(nll.min(dim=1)[1].eq(batch['labels'].cuda()).int().sum().item())\n",
    "                # print(nll[1])\n",
    "\n",
    "                perlabel_nlls.append(nll)\n",
    "                del new_batch\n",
    "        \n",
    "            nll = torch.stack(perlabel_nlls, dim=1) # bsz x label_size\n",
    "            nlls.append(nll)\n",
    "\n",
    "        nll = torch.stack(nlls, dim=2)\n",
    "        nll = -torch.logsumexp(-nll, dim=-1) + np.log(num_labelstrings)\n",
    "\n",
    "        nll = nll.min(dim=1)\n",
    "        # print(nll[1])\n",
    "\n",
    "        accurate += nll[1].eq(batch['labels'].cuda()).int().sum().item()\n",
    "        total += nll[1].size(0)\n",
    "        all_predictions += nll[1].tolist()\n",
    "        all_labels += batch['labels'].tolist()\n",
    "        # print(all_predictions)\n",
    "        # print(all_labels)\n",
    "        # print(accurate, \"/\", nll[1].size(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yelp Polarity: 31487/38000, 0.8286052631578947\n"
     ]
    }
   ],
   "source": [
    "print(f\"Yelp Polarity: {accurate}/{total}, {accurate/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2: 31487/38000, 0.8286052631578947\n"
     ]
    }
   ],
   "source": [
    "print(f\"SST-2: {accurate}/{total}, {accurate/total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SST-2: 747/872, 0.856651376146789\n",
    "# Yelp Polarity: 31487/38000, 0.8286052631578947\n",
    "# # alllabelstrings = [\n",
    "# #     [  \n",
    "# #         \"This review exhibits a negative bias.\",\n",
    "# #         \"The inclination of this review is towards the negative side.\",\n",
    "# #         \"There is a unfavorable slant in this review.\",\n",
    "# #         \"The overall tone of this review is negative.\",\n",
    "# #         \"This review shows a leaning against the subject.\",\n",
    "# #         \"There is a negative inclination in this review.\",\n",
    "# #         \"The overall impression of this review is pessimistic.\",\n",
    "# #         \"This review tends to disfavor the subject being discussed.\",\n",
    "# #         \"There is a negative inclination evident in this review.\",\n",
    "# #         \"The general sentiment of this review is negative.\",\n",
    "# #     ],\n",
    "# #     [\n",
    "# #         \"This review exhibits a positive bias.\",\n",
    "# #         \"The inclination of this review is towards the positive side.\",\n",
    "# #         \"There is a favorable slant in this review.\",\n",
    "# #         \"The overall tone of this review is positive.\",\n",
    "# #         \"This review shows a leaning in favor of the subject.\",\n",
    "# #         \"There is a positive inclination in this review.\",\n",
    "# #         \"The overall impression of this review is optimistic.\",\n",
    "# #         \"This review tends to favor the subject being discussed.\",\n",
    "# #         \"There is a positive inclination evident in this review.\",\n",
    "# #         \"The general sentiment of this review is positive.\",\n",
    "# #     ]\n",
    "# # ]\n",
    "\n",
    "# # alllabelstrings = [[\"This review is leaning negative. \"], [\"This review is leaning positive. \"]]\n",
    "# # alllabelstrings = [[\"This review criticizes. \"], [\"This review appreciates. \"]]\n",
    "\n",
    "# alllabelstrings = [\n",
    "#     [  \n",
    "#         \"This review exhibits a negative intent.\",\n",
    "#         #\"The inclination of this review is towards the negative side.\",\n",
    "#         #\"There is a unfavorable slant in this review.\",\n",
    "#         # \"The overall tone of this review is negative.\",\n",
    "#         # \"This review shows a leaning against the subject.\",\n",
    "#         \"There is a negative inclination in this review.\",\n",
    "#         # \"The overall impression of this review is pessimistic.\",\n",
    "#         # \"This review tends to disfavor the subject being discussed.\",\n",
    "#         # \"There is a negative inclination evident in this review.\",\n",
    "#         # \"The general sentiment of this review is negative.\",\n",
    "#     ],\n",
    "#     [\n",
    "#         \"This review exhibits a positive intent.\",\n",
    "#         #\"The inclination of this review is towards the positive side.\",\n",
    "#         #\"There is a favorable slant in this review.\",\n",
    "#         # \"The overall tone of this review is positive.\",\n",
    "#         # \"This review shows a leaning in favor of the subject.\",\n",
    "#         \"There is a positive inclination in this review.\",\n",
    "#         # \"The overall impression of this review is optimistic.\",\n",
    "#         # \"This review tends to favor the subject being discussed.\",\n",
    "#         # \"There is a positive inclination evident in this review.\",\n",
    "#         # \"The general sentiment of this review is positive.\",\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# num_labels = len(alllabelstrings)\n",
    "# num_labelstrings = [len(labelstrings) for labelstrings in alllabelstrings]\n",
    "\n",
    "# merged_labelstrings = []\n",
    "# for labelstrings in alllabelstrings:\n",
    "#     merged_labelstrings += labelstrings\n",
    "\n",
    "# tokenizer.padding_side = \"left\"\n",
    "# merged_labelstrings_tokenized = tokenizer(merged_labelstrings, add_special_tokens=False, padding=True, return_tensors=\"pt\").to(device)\n",
    "# tokenizer.padding_side = \"right\"\n",
    "\n",
    "# print(len(merged_labelstrings))\n",
    "# print(merged_labelstrings_tokenized['input_ids'].size())\n",
    "# for key in merged_labelstrings_tokenized:\n",
    "#     merged_labelstrings_tokenized[key] = merged_labelstrings_tokenized[key].view(num_labels, num_labelstrings[0], -1)\n",
    "\n",
    "# tokenizer.pad_token = tokenizer.eos_token    \n",
    "# tokenizer.pad_token_id = tokenizer.eos_token_id\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
