{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import sys \n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    \"sentiment2/glue-sst2\", \n",
    "    \"sentiment5/SetFit/sst5-None\",\n",
    "    \"sentiment2-yelp/yelp_polarity-None\",\n",
    "    \"sentiment5-yelp/yelp_review_full-None\", \n",
    "    \"sentiment2-amazon/amazon_polarity-None\",\n",
    "    \"sentiment2-mr/rotten_tomatoes-None\",\n",
    "    \"sentiment2-cr/SetFit/CR-None\",\n",
    "    \"tweet_eval-sentiment/tweet_eval-None\",\n",
    "    \"finance_sentiment3/financial_phrasebank-None\",\n",
    "    \"poemsentiment2/poem_sentiment-None\",\n",
    "    \"agnews/ag_news-None\",\n",
    "    \"dbpedia/dbpedia_14-None\",\n",
    "    \"hate_speech18/hate_speech18-None\",\n",
    "    \"tweet_eval-hate/tweet_eval-None\",\n",
    "    \"ethos-national_origin/ethos-national_origin-None2\",\n",
    "    \"ethos-sexual_orientation/ethos-sexual_orientation-None2\",\n",
    "    \"ethos-race/ethos-race-None2\",\n",
    "    \"ethos-religion/ethos-religion-None2\",\n",
    "    \"emotion6/dair-ai/emotion-None\",\n",
    "    ]\n",
    "task_names = [\n",
    "    \"SST2\",\n",
    "    \"SST5\",\n",
    "    \"Yelp2\",\n",
    "    \"Yelp5\",\n",
    "    \"Amazon2\",\n",
    "    \"MR\",\n",
    "    \"CR\",\n",
    "    \"Tweet3\",\n",
    "    \"FP\",\n",
    "    \"PS\", \n",
    "    \"AGNews\",\n",
    "    \"DBPedia\", \n",
    "    \"HS18\",\n",
    "    \"Tweet\",\n",
    "    \"Ethos (NO)\",\n",
    "    \"Ethos (SO)\",\n",
    "    \"Ethos (Race)\",\n",
    "    \"Ethos (Religion)\", \n",
    "    \"Emotions\"\n",
    "]\n",
    "models = [\n",
    "    \"gpt2\", \n",
    "    \"gpt2-medium\", \n",
    "    \"gpt2-large\", \n",
    "    \"gpt2-xl\", \n",
    "    \"facebook/opt-1.3b\", \n",
    "    \"facebook/opt-2.7b\", \n",
    "    \"EleutherAI/pythia-1.4b\", \n",
    "    \"EleutherAI/pythia-2.8b\", \n",
    "    \"EleutherAI/pythia-6.7b\",\n",
    "    \"EleutherAI/pythia-12b\",\n",
    "    \"EleutherAI/gpt-j-6b\",\n",
    "    \"huggyllama/llama-7b\",\n",
    "    \"huggyllama/llama-13b\",\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    \"meta-llama/Llama-2-13b-hf\",\n",
    "    ]\n",
    "\n",
    "approaches = [\"channel-simple\", \"direct-simple\", \"direct-context\", \"direct-instruct\"]\n",
    "has_pp = [False, True, True, True]\n",
    "num_tasks = len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_std(lines_main, lines_text, prefix, task, metric, arithmetic, geometric, harmonic, metric2, arithmetic2, geometric2, harmonic2):\n",
    "\n",
    "    x, yarith_mean, yarith_std, F1arith_mean, F1arith_std = get_stats(lines_main, prefix, arithmetic, metric)\n",
    "    x, ygeo_mean, ygeo_std, F1geo_mean, F1geo_std = get_stats(lines_main, prefix, geometric, metric)\n",
    "    x, yharm_mean, yharm_std, F1harm_mean, F1harm_std = get_stats(lines_main, prefix, harmonic, metric)\n",
    "\n",
    "    return_object = [np.array(x), yarith_mean, ygeo_mean, yharm_mean, yarith_std, ygeo_std, yharm_std]\n",
    "    return_objectf1 = [np.array(x), F1arith_mean, F1geo_mean, F1harm_mean, F1arith_std, F1geo_std, F1harm_std]\n",
    "\n",
    "    # if plot:\n",
    "    #     plt.errorbar(x, yarith_mean, yarith_std, color=\"blue\", label=\"Arithmetic\")\n",
    "    #     plt.errorbar(x, ygeo_mean, ygeo_std, color=\"red\", label=\"Geometric\")\n",
    "    #     plt.errorbar(x, yharm_mean, yharm_std, color=\"green\", label=\"Harmonic\")\n",
    "\n",
    "    # if x is not None:\n",
    "    #     print(f'{task}, {prefix} & {(F1arith_mean[-2] * 100):.1f}$_{{({(F1arith_std[-2]*100):.2f})}}$')\n",
    "    # else:\n",
    "    #     print(f'{task}, {prefix} & NA')\n",
    "\n",
    "    #print(lines_text)\n",
    "    x, yarith_mean, yarith_std, F1arith_mean, F1arith_std = get_stats(lines_text, prefix, arithmetic2, metric2)\n",
    "    x, ygeo_mean, ygeo_std, F1geo_mean, F1geo_std = get_stats(lines_text, prefix, geometric2, metric2)\n",
    "    x, yharm_mean, yharm_std, F1harm_mean, F1harm_std = get_stats(lines_text, prefix, harmonic2, metric2)\n",
    "\n",
    "    # if x is not None:\n",
    "    #     print(f'{task}-text, {prefix} & {(yarith_mean[-2] * 100):.1f}$_{{({(yarith_std[-2]*100):.2f})}}$')\n",
    "    # else:\n",
    "    #     print(f'{task}-text, {prefix} & NA')\n",
    "\n",
    "    return_object += [yarith_mean, ygeo_mean, yharm_mean, yarith_std, ygeo_std, yharm_std]\n",
    "    return_objectf1 += [F1arith_mean, F1geo_mean, F1harm_mean, F1arith_std, F1geo_std, F1harm_std]\n",
    "\n",
    "    return return_object, return_objectf1\n",
    "\n",
    "    # if plot:\n",
    "    #     plt.errorbar(x, yarith_mean, yarith_std, color=\"blue\", label=\"Arithmetic (w/o domain)\")\n",
    "    #     plt.errorbar(x, ygeo_mean, ygeo_std, color=\"red\", label=\"Geometric (w/o domain)\")\n",
    "    #     plt.errorbar(x, yharm_mean, yharm_std, color=\"green\", label=\"Harmonic (w/o domain)\")\n",
    "\n",
    "    #     plt.legend(loc=\"best\")\n",
    "    #     plt.savefig(save_figfile)\n",
    "    #     plt.clf()\n",
    "    #input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_fscore(confusion_matrix, i):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for j in range(len(confusion_matrix)):\n",
    "        if (i == j):\n",
    "            TP += confusion_matrix[i][j]\n",
    "            tmp = np.delete(confusion_matrix, i, 0)\n",
    "            tmp = np.delete(tmp, j, 1)\n",
    "\n",
    "            TN += np.sum(tmp)\n",
    "        else:\n",
    "            if (confusion_matrix[i][j] != 0):\n",
    "\n",
    "                FN += confusion_matrix[i][j]\n",
    "            if (confusion_matrix[j][i] != 0):\n",
    "\n",
    "                FP += confusion_matrix[j][i]\n",
    "\n",
    "    recall = TP / (FN + TP + 1e-10)\n",
    "    precision = TP / (TP + FP + 1e-10)\n",
    "    f1_score = 2 * 1/(1/(recall + 1e-10) + 1/(precision + 1e-10))\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "def f1_score(confusion_matrix, macro=\"True\"):\n",
    "    Ps, Rs, F1s = [], [], []\n",
    "    for i in range(len(confusion_matrix)):\n",
    "        p, r, f1 = precision_recall_fscore(confusion_matrix, i)\n",
    "        Ps.append(p)\n",
    "        Rs.append(r)\n",
    "        F1s.append(f1)\n",
    "    \n",
    "    return Ps, Rs, F1s, np.mean(F1s)\n",
    "\n",
    "def get_stats(lines, prefix, suffix, metric):\n",
    "    y = []\n",
    "    F1 = []\n",
    "    x = None\n",
    "    c = 0\n",
    "    for line in lines:\n",
    "        try:\n",
    "            items = json.loads(line)\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            print(e)\n",
    "            input(line)\n",
    "            raise ValueError\n",
    "        if x is None:\n",
    "            x = items['k']\n",
    "        y.append(items[prefix+f\"{metric}\"+suffix])\n",
    "\n",
    "        tmp = items[prefix+\"confusion_matrix\"+suffix]\n",
    "        new_temp = []\n",
    "        for item in tmp:\n",
    "            temp_item = item.replace(\"\\n\", \"\")\n",
    "            while \"[ \" in temp_item:\n",
    "                temp_item = temp_item.replace(\"[ \", \"[\")\n",
    "            while \"  \" in temp_item:\n",
    "                temp_item = temp_item.replace(\"  \", \" \")\n",
    "            new_temp.append(eval(temp_item.replace(\" \", \",\")))\n",
    "        tmp = new_temp\n",
    "        # tmp = [eval(item.replace(\"\\n\", \"\").replace(\"[ \", \"[\").replace(\"[ \", \"[\").replace(\"  \", \" \").replace(\" \", \",\")) for item in tmp]\n",
    "        F1.append([f1_score(cm)[-1] for cm in tmp])\n",
    "\n",
    "    if len(F1) > 0:\n",
    "        y_mean  = np.mean(y, axis=0)\n",
    "        y_std = np.std(y, axis=0)\n",
    "        F1_mean  = np.mean(F1, axis=0)\n",
    "        F1_std = np.std(F1, axis=0)\n",
    "\n",
    "        return x[:10], y_mean[:10], y_std[:10], F1_mean[:10], F1_std[:10]\n",
    "    else:\n",
    "        print(lines)\n",
    "        input()\n",
    "        return None, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gpt2\n",
      "model: gpt2-medium\n",
      "model: gpt2-large\n",
      "model: gpt2-xl\n",
      "model: facebook/opt-1.3b\n",
      "model: facebook/opt-2.7b\n",
      "model: EleutherAI/pythia-1.4b\n",
      "model: EleutherAI/pythia-2.8b\n",
      "model: EleutherAI/pythia-6.7b\n",
      "model: EleutherAI/pythia-12b\n",
      "./results/0923/direct-simple/dbpedia/dbpedia_14-None/EleutherAI/pythia-12b/results.jsonl is empty. Skipping\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 0 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 1 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 2 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 3 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 4 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 5 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 6 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 7 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 8 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 9 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 10 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 11 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 12 'dbpedia/dbpedia_14-None'\n",
      "./results/0923/direct-context/dbpedia/dbpedia_14-None/EleutherAI/pythia-12b/results.jsonl is empty. Skipping\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 0 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 1 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 2 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 3 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 4 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 5 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 6 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 7 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 8 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 9 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 10 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 11 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 12 'dbpedia/dbpedia_14-None'\n",
      "./results/0923/direct-instruct/dbpedia/dbpedia_14-None/EleutherAI/pythia-12b/results.jsonl is empty. Skipping\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 0 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 1 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 2 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 3 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 4 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 5 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 6 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 7 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 8 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 9 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 10 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 11 'dbpedia/dbpedia_14-None'\n",
      "something happend to EleutherAI/pythia-12b dbpedia/dbpedia_14-None item 12 'dbpedia/dbpedia_14-None'\n",
      "model: EleutherAI/gpt-j-6b\n",
      "model: huggyllama/llama-7b\n",
      "model: huggyllama/llama-13b\n",
      "model: meta-llama/Llama-2-7b-hf\n",
      "model: meta-llama/Llama-2-13b-hf\n",
      "./results/0923/direct-instruct/dbpedia/dbpedia_14-None/meta-llama/Llama-2-13b-hf/results.jsonl is empty. Skipping\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 0 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 1 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 2 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 3 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 4 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 5 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 6 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 7 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 8 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 9 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 10 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 11 'dbpedia/dbpedia_14-None'\n",
      "something happend to meta-llama/Llama-2-13b-hf dbpedia/dbpedia_14-None item 12 'dbpedia/dbpedia_14-None'\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "import os\n",
    "prefix_channel=\"\"\n",
    "prefix_direct=\"direct_\"\n",
    "prefix_directplusplus=\"direct++_\"\n",
    "notdone = {}\n",
    "for model in models:\n",
    "    notdone[model] = {}\n",
    "    # if \"pythia\" in model:\n",
    "    #     break\n",
    "    print(\"model: \"+model)\n",
    "    results[model] = {}\n",
    "    for i, approach in enumerate(approaches):\n",
    "        notdone[model][approach] = {'main': [], 'text': []}\n",
    "        if \"direct\" in approach:\n",
    "            results[model][approach] = {\"direct\": {\"mean\": [0 for _ in range(13)], \"mean_f1\": [0 for _ in range(13)]}, \n",
    "                                        \"direct++\": {\"mean\": [0 for _ in range(13)], \"mean_f1\": [0 for _ in range(13)]}}\n",
    "        else:\n",
    "            results[model][approach] = {\"channel\": {\"mean\": [0 for _ in range(13)], \"mean_f1\": [0 for _ in range(13)]}}\n",
    "\n",
    "        for task in tasks:\n",
    "            # print(task)\n",
    "            # for key in results[model][approach]:\n",
    "            #     results[model][approach][key][task] = {}\n",
    "            filename_main = f\"./results/0923/{approach}/{task}/{model}/results.jsonl\"\n",
    "            filename_text = f\"./results/0923-ablations/{approach}/{task}/{model}/results.jsonl\"            \n",
    "            \n",
    "            try:\n",
    "                lines_main = open(filename_main).readlines()\n",
    "            except:\n",
    "                notdone[model][approach]['main'].append(task)\n",
    "                print(f\"{filename_main} does not exist. Skipping\")\n",
    "                continue\n",
    "\n",
    "            if len(lines_main) == 0:\n",
    "                notdone[model][approach]['main'].append(task)\n",
    "                print(f\"{filename_main} is empty. Skipping\")\n",
    "                continue\n",
    "            # print(filename_main, filename_text)\n",
    "            try:\n",
    "                lines_text = open(filename_text).readlines()\n",
    "            except:\n",
    "                lines_text = open(filename_main).readlines()\n",
    "                notdone[model][approach]['text'].append(task)\n",
    "                # print(f\"{filename_text} does not exist. So using the same file in both. BEWARE\")\n",
    "                # continue\n",
    "\n",
    "            if len(lines_text) == 0:\n",
    "                notdone[model][approach]['text'].append(task)\n",
    "                lines_text = lines_main\n",
    "                # print(f\"{filename_text} is empty. So using the same file in both. BEWARE\")\n",
    "\n",
    "            # print(filename_main)\n",
    "            try:\n",
    "                metric_name = json.loads(lines_main[0])['metric_name']\n",
    "                metric = \"metric\"\n",
    "                arithmetic = \"_arithmetic\"\n",
    "                geometric = \"_geometric\"\n",
    "                harmonic = \"_harmonic\"\n",
    "            except:\n",
    "                arithmetic = \"_logsumexp\"\n",
    "                geometric = \"_average\"\n",
    "                harmonic = \"_vote\"\n",
    "                metric_name = \"accuracy\"\n",
    "                metric = \"accuracy\"\n",
    "\n",
    "            try:\n",
    "                metric_name2 = json.loads(lines_text[0])['metric_name']\n",
    "                metric2 = \"metric\"\n",
    "                arithmetic2 = \"_arithmetic\"\n",
    "                geometric2 = \"_geometric\"\n",
    "                harmonic2 = \"_harmonic\"\n",
    "            except:\n",
    "                arithmetic2 = \"_logsumexp\"\n",
    "                geometric2 = \"_average\"\n",
    "                harmonic2 = \"_vote\"\n",
    "                metric_name2 = \"accuracy\"\n",
    "                metric2 = \"accuracy\"\n",
    "\n",
    "            if \"channel\" in approach:\n",
    "                # os.makedirs(f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}/', exist_ok=True)\n",
    "                # save_figfile = f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}/{task.replace(\"/\", \"-\")}-{metric}.png'\n",
    "                acc, f1 = compute_mean_std(lines_main, lines_text, \"\", task, metric, arithmetic, geometric, harmonic, metric2, arithmetic2, geometric2, harmonic2)\n",
    "                results[model][approach][\"channel\"][task] = acc\n",
    "                results[model][approach][\"channel\"][task+'_f1'] = f1\n",
    "            else:\n",
    "                # os.makedirs(f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}/', exist_ok=True)\n",
    "                # save_figfile = f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}/{task.replace(\"/\", \"-\")}.png'\n",
    "                acc, f1 = compute_mean_std(lines_main, lines_text, \"direct_\", task, metric, arithmetic, geometric, harmonic, metric2, arithmetic2, geometric2, harmonic2)\n",
    "                results[model][approach][\"direct\"][task] = acc\n",
    "                results[model][approach][\"direct\"][task+\"_f1\"] = f1\n",
    "\n",
    "                # os.makedirs(f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}++/', exist_ok=True)\n",
    "                # save_figfile = f'./results/0923/plots/{model.replace(\"/\", \"-\")}/{approach}++/{task.replace(\"/\", \"-\")}.png'\n",
    "                acc, f1 = compute_mean_std(lines_main, lines_text, \"direct++_\", task, metric, arithmetic, geometric, harmonic, metric2, arithmetic2, geometric2, harmonic2)\n",
    "                results[model][approach][\"direct++\"][task] = acc\n",
    "                results[model][approach][\"direct++\"][task+\"_f1\"] = f1\n",
    "\n",
    "            # input()\n",
    "        for task in tasks:\n",
    "            for j in range(13):\n",
    "                # print(j)\n",
    "                try:\n",
    "                    if \"channel\" in approach:\n",
    "                        results[model][approach][\"channel\"][\"mean\"][j] = results[model][approach][\"channel\"][\"mean\"][j] + results[model][approach][\"channel\"][task][j]\n",
    "                        results[model][approach][\"channel\"][\"mean_f1\"][j] = results[model][approach][\"channel\"][\"mean_f1\"][j] + results[model][approach][\"channel\"][task+\"_f1\"][j]\n",
    "                    else:\n",
    "                        #if results[model][approach][approach][task][j] is not None and results[model][approach][approach+\"++\"][task][j] is not None:\n",
    "                        results[model][approach][\"direct\"][\"mean\"][j] = results[model][approach][\"direct\"][\"mean\"][j] + results[model][approach][\"direct\"][task][j]\n",
    "                        results[model][approach][\"direct\"][\"mean_f1\"][j] = results[model][approach][\"direct\"][\"mean_f1\"][j] + results[model][approach][\"direct\"][task+\"_f1\"][j]\n",
    "\n",
    "                        results[model][approach][\"direct++\"][\"mean\"][j] = results[model][approach][\"direct++\"][\"mean\"][j] + results[model][approach][\"direct++\"][task][j]\n",
    "                        results[model][approach][\"direct++\"][\"mean_f1\"][j] = results[model][approach][\"direct++\"][\"mean_f1\"][j] + results[model][approach][\"direct++\"][task+\"_f1\"][j]\n",
    "                        # c += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"something happend to {model} {task} item {j} {e}\")\n",
    "                    # print(e)\n",
    "                    # input()\n",
    "                    \n",
    "                    # break\n",
    "                    # continue\n",
    "            # print(tasks)\n",
    "        # break\n",
    "    # break\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: gpt2\n",
      "./results/0923/plots/iclr/channel-simple/gpt2_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: gpt2-medium\n",
      "./results/0923/plots/iclr/channel-simple/gpt2-medium_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-medium_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-medium_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-medium_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-medium_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-medium_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-medium_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: gpt2-large\n",
      "./results/0923/plots/iclr/channel-simple/gpt2-large_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-large_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-large_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-large_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-large_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-large_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-large_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: gpt2-xl\n",
      "./results/0923/plots/iclr/channel-simple/gpt2-xl_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-xl_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/gpt2-xl_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-xl_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/gpt2-xl_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-xl_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/gpt2-xl_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: facebook/opt-1.3b\n",
      "./results/0923/plots/iclr/channel-simple/facebook-opt-1.3b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/facebook-opt-1.3b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/facebook-opt-1.3b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/facebook-opt-1.3b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/facebook-opt-1.3b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/facebook-opt-1.3b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/facebook-opt-1.3b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: facebook/opt-2.7b\n",
      "./results/0923/plots/iclr/channel-simple/facebook-opt-2.7b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/facebook-opt-2.7b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/facebook-opt-2.7b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/facebook-opt-2.7b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/facebook-opt-2.7b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/facebook-opt-2.7b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/facebook-opt-2.7b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: EleutherAI/pythia-1.4b\n",
      "./results/0923/plots/iclr/channel-simple/EleutherAI-pythia-1.4b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-1.4b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-1.4b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-1.4b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-1.4b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-1.4b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-1.4b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: EleutherAI/pythia-2.8b\n",
      "./results/0923/plots/iclr/channel-simple/EleutherAI-pythia-2.8b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-2.8b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-2.8b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-2.8b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-2.8b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-2.8b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-2.8b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: EleutherAI/pythia-6.7b\n",
      "./results/0923/plots/iclr/channel-simple/EleutherAI-pythia-6.7b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-6.7b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-6.7b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-6.7b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-6.7b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-6.7b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-6.7b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: EleutherAI/pythia-12b\n",
      "./results/0923/plots/iclr/channel-simple/EleutherAI-pythia-12b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-12b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-pythia-12b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-12b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-pythia-12b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-12b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-pythia-12b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: EleutherAI/gpt-j-6b\n",
      "./results/0923/plots/iclr/channel-simple/EleutherAI-gpt-j-6b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "0 0.28668910107840107 0.007522488801828302\n",
      "1 0.29890882821742143 0.00659413385602525\n",
      "2 0.30308905099470074 0.005958354458580185\n",
      "3 0.30543039874510297 0.005965326088587602\n",
      "4 0.30682807167299603 0.0051967260600977935\n",
      "5 0.3088086398757933 0.005288530643277464\n",
      "6 0.3083478539865299 0.0045094766060624885\n",
      "7 0.3091154882373397 0.003490763052054586\n",
      "8 0.3093598387351057 0.0031935916015814795\n",
      "9 0.31025844639478645 0.002512076714614188\n",
      "\n",
      "0 0.2734338461554366 0.0073199142639442105\n",
      "1 0.2864792830404578 0.006072152155163658\n",
      "2 0.29155476978689343 0.006150717361293702\n",
      "3 0.2958979691433672 0.006594514793919819\n",
      "4 0.2980713456482307 0.005522961322403963\n",
      "5 0.29917044950288246 0.005850254956199279\n",
      "6 0.29940506576818804 0.0046993278480642565\n",
      "7 0.2990845961755857 0.00384790872849863\n",
      "8 0.3003145948863678 0.003203790201849621\n",
      "9 0.30082383816213987 0.0026617674016227444\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-gpt-j-6b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "0 0.20598788051547676 0.008518971855149651\n",
      "1 0.20871059218312332 0.007647319014798358\n",
      "2 0.2084229688367575 0.006585871824777716\n",
      "3 0.20949321496942863 0.00658766355368912\n",
      "4 0.20838917360570614 0.006364923666413276\n",
      "5 0.20744151739826006 0.005976140155019394\n",
      "6 0.20575920547466175 0.004941388147516345\n",
      "7 0.20520988801030526 0.004829339043800783\n",
      "8 0.20475012421901093 0.003388846190589707\n",
      "9 0.20338752480986977 0.0025510569936441282\n",
      "\n",
      "0 0.21214957854119426 0.008019043950766804\n",
      "1 0.2200225961058136 0.007433019633064267\n",
      "2 0.2225800462588005 0.006680088849201149\n",
      "3 0.22548802611680324 0.006399970283906714\n",
      "4 0.22593331295574287 0.006066330133304042\n",
      "5 0.22623566992166486 0.005719925223135098\n",
      "6 0.22519715052677744 0.005023625887019826\n",
      "7 0.22566366211741912 0.004696300085777709\n",
      "8 0.2261972909588461 0.003236516120375113\n",
      "9 0.22573236572022096 0.0025473971976378187\n",
      "./results/0923/plots/iclr/direct-simple/EleutherAI-gpt-j-6b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "0 0.25664631911967944 0.009249558350080043\n",
      "1 0.26218444227874144 0.008431043736402855\n",
      "2 0.2618683085022007 0.008425135771202802\n",
      "3 0.2650621503587521 0.007514640923071305\n",
      "4 0.2630688668423693 0.007350100512480642\n",
      "5 0.2648210456294487 0.006418236984946511\n",
      "6 0.2650693000254371 0.005683894854595488\n",
      "7 0.26619221346792515 0.004772869841256476\n",
      "8 0.2667976565467961 0.004590534869274052\n",
      "9 0.2663499714039562 0.003590196392289679\n",
      "\n",
      "0 0.2525187930812653 0.008400755557566269\n",
      "1 0.25853018229730973 0.009030286295071202\n",
      "2 0.2586762695394427 0.008719244013072603\n",
      "3 0.26114195959906084 0.006650058167611444\n",
      "4 0.2621504562668185 0.007585808366080827\n",
      "5 0.26384435328533296 0.006596883953463735\n",
      "6 0.2640396683065012 0.005741208474873887\n",
      "7 0.2658362424640675 0.0050302441166630435\n",
      "8 0.2671631753059151 0.004259642892024967\n",
      "9 0.2668806028582286 0.003622888687445906\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-gpt-j-6b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "0 0.2134942506745377 0.007938903153990585\n",
      "1 0.21823909178685455 0.008115640562926154\n",
      "2 0.21906796760381825 0.007620858581559574\n",
      "3 0.21744240442323665 0.006124555887688193\n",
      "4 0.2162552560532784 0.005825791582868415\n",
      "5 0.21524382376213472 0.005340548464712364\n",
      "6 0.21340930927825713 0.005180541617595143\n",
      "7 0.2123245194804689 0.004171456253673743\n",
      "8 0.21006643517534748 0.0034936332283257827\n",
      "9 0.20891750642122142 0.0029203836744903277\n",
      "\n",
      "0 0.21411401642909925 0.007593142031853144\n",
      "1 0.22269860648718381 0.007838980407306686\n",
      "2 0.22697195979697926 0.006898068765286\n",
      "3 0.22812881006402516 0.005665752357971883\n",
      "4 0.22963464896156544 0.00536283923275916\n",
      "5 0.23004215086614507 0.0049994552222552575\n",
      "6 0.23036710751201425 0.004993514802923458\n",
      "7 0.23058973216652073 0.0038466768657080047\n",
      "8 0.2302228714646346 0.0033087678981049556\n",
      "9 0.2299704592199649 0.002384193986129559\n",
      "./results/0923/plots/iclr/direct-context/EleutherAI-gpt-j-6b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "0 0.2658987803478694 0.009009612525174794\n",
      "1 0.2721287960679049 0.007927110211174062\n",
      "2 0.2736572860123611 0.009240454030890329\n",
      "3 0.2730355208365529 0.0064768845122170435\n",
      "4 0.2742917520363549 0.007647961663270314\n",
      "5 0.27361847245417004 0.005611150606785898\n",
      "6 0.2744252424548185 0.006137557339066723\n",
      "7 0.2741468729595075 0.004726495198193877\n",
      "8 0.27450361670481194 0.0038777057657571035\n",
      "9 0.27323145398857396 0.0031392985550058525\n",
      "\n",
      "0 0.26120894764214764 0.00894920529150277\n",
      "1 0.26757701532079325 0.007801441034845066\n",
      "2 0.2696145924608039 0.008758383153478782\n",
      "3 0.27151477102903165 0.006757049035962669\n",
      "4 0.2737653157259461 0.00638781516524287\n",
      "5 0.274289526904797 0.005826534433660155\n",
      "6 0.27575249033870997 0.005126113737625946\n",
      "7 0.27588936657202134 0.004728005956880226\n",
      "8 0.27648585446566465 0.004189400413821753\n",
      "9 0.2766152603018167 0.0031010371494007917\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-gpt-j-6b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "0 0.1887135764915864 0.0071473239853962756\n",
      "1 0.19427251890278016 0.0065955767252938394\n",
      "2 0.19557859438826747 0.006732599718645697\n",
      "3 0.19580620822314557 0.006094331314456213\n",
      "4 0.19386222658965477 0.005684743462097608\n",
      "5 0.19396038506574312 0.005543256391539063\n",
      "6 0.19187659509526653 0.004223304223412976\n",
      "7 0.1912033920749985 0.0034960439459049766\n",
      "8 0.1913753105454259 0.0031685365295334306\n",
      "9 0.19165894912663833 0.002053296215744567\n",
      "\n",
      "0 0.19469174307558115 0.006666681340073734\n",
      "1 0.2036583518580251 0.006411173912165844\n",
      "2 0.20831060417755434 0.006145090851951919\n",
      "3 0.20899555009146947 0.005939496634775282\n",
      "4 0.20740708529574298 0.00555971394927199\n",
      "5 0.2061902100322332 0.005692427675863294\n",
      "6 0.2054254078392817 0.003946568946792888\n",
      "7 0.20387159526715468 0.0035442083241407503\n",
      "8 0.20316764200874 0.0024553724231628064\n",
      "9 0.2017915147311197 0.0018979373968583302\n",
      "./results/0923/plots/iclr/direct-instruct/EleutherAI-gpt-j-6b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "0 0.2104745134160217 0.007388628062342799\n",
      "1 0.20173745642136637 0.00597610957357793\n",
      "2 0.1983474774777131 0.004943650802990854\n",
      "3 0.1959686677454205 0.004682527733865024\n",
      "4 0.1943816572186476 0.0041415842271653605\n",
      "5 0.1935686295628958 0.003575158973370153\n",
      "6 0.1919434561812897 0.003816774509152452\n",
      "7 0.19115260211128365 0.0026443903904217426\n",
      "8 0.19021548769567442 0.0023421743084688835\n",
      "9 0.1894363969959452 0.0016732022214940967\n",
      "\n",
      "0 0.21165257312262642 0.007775891800379261\n",
      "1 0.20457209288925945 0.006626886540575643\n",
      "2 0.20065287225195322 0.005604772438827106\n",
      "3 0.20053492244134308 0.0047690524857651375\n",
      "4 0.1986512347546425 0.004516249415596012\n",
      "5 0.19772849004062745 0.0034281264788590025\n",
      "6 0.19692371192873467 0.003252166921636356\n",
      "7 0.1967447610405457 0.0027929531449584107\n",
      "8 0.1954657287716346 0.002478670085826578\n",
      "9 0.1954447392710869 0.0018169238087321015\n",
      "model: huggyllama/llama-7b\n",
      "./results/0923/plots/iclr/channel-simple/huggyllama-llama-7b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/huggyllama-llama-7b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/huggyllama-llama-7b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/huggyllama-llama-7b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/huggyllama-llama-7b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/huggyllama-llama-7b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/huggyllama-llama-7b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: huggyllama/llama-13b\n",
      "./results/0923/plots/iclr/channel-simple/huggyllama-llama-13b_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/huggyllama-llama-13b_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/huggyllama-llama-13b_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/huggyllama-llama-13b_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/huggyllama-llama-13b_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/huggyllama-llama-13b_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/huggyllama-llama-13b_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: meta-llama/Llama-2-7b-hf\n",
      "./results/0923/plots/iclr/channel-simple/meta-llama-Llama-2-7b-hf_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/meta-llama-Llama-2-7b-hf_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/meta-llama-Llama-2-7b-hf_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/meta-llama-Llama-2-7b-hf_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/meta-llama-Llama-2-7b-hf_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/meta-llama-Llama-2-7b-hf_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/meta-llama-Llama-2-7b-hf_direct-instruct_direct++_all-tasks-mean-accuracy.png\n",
      "model: meta-llama/Llama-2-13b-hf\n",
      "./results/0923/plots/iclr/channel-simple/meta-llama-Llama-2-13b-hf_channel-simple_channel_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/meta-llama-Llama-2-13b-hf_direct-simple_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-simple/meta-llama-Llama-2-13b-hf_direct-simple_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/meta-llama-Llama-2-13b-hf_direct-context_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-context/meta-llama-Llama-2-13b-hf_direct-context_direct++_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/meta-llama-Llama-2-13b-hf_direct-instruct_direct_all-tasks-mean-accuracy.png\n",
      "./results/0923/plots/iclr/direct-instruct/meta-llama-Llama-2-13b-hf_direct-instruct_direct++_all-tasks-mean-accuracy.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(\"model: \"+model)\n",
    "    \n",
    "    for i, approach in enumerate(approaches):\n",
    "        if \"channel\" in approach:\n",
    "            lengths = [len(results[model][approach][\"channel\"])]\n",
    "            keys = [\"channel\"]\n",
    "        else:\n",
    "            lengths = [len(results[model][approach][\"direct\"])]\n",
    "            lengths += [len(results[model][approach][\"direct++\"])]\n",
    "            keys = [\"direct\", \"direct++\"]\n",
    "        os.makedirs(f'./results/0923/plots/iclr/{approach}', exist_ok=True)\n",
    "        for key, length in zip(keys, lengths):\n",
    "            save_figfile = f'./results/0923/plots/iclr/{approach}/{model.replace(\"/\", \"-\")}_{approach}_{key}_all-tasks-mean-accuracy.png'\n",
    "            # print(save_figfile)\n",
    "            x = results[model][approach][key][\"mean\"][0]/length\n",
    "            \n",
    "            main_arith = results[model][approach][key][\"mean\"][1]/length\n",
    "            main_geo = results[model][approach][key][\"mean\"][2]/length\n",
    "            main_harm = results[model][approach][key][\"mean\"][3]/length\n",
    "\n",
    "            main_arith_std = results[model][approach][key][\"mean\"][4]/length\n",
    "            main_geo_std = results[model][approach][key][\"mean\"][5]/length\n",
    "            main_harm_std = results[model][approach][key][\"mean\"][6]/length\n",
    "\n",
    "            text_arith = results[model][approach][key][\"mean\"][7]/length\n",
    "            text_geo = results[model][approach][key][\"mean\"][8]/length\n",
    "            text_harm = results[model][approach][key][\"mean\"][9]/length\n",
    "\n",
    "            text_arith_std = results[model][approach][key][\"mean\"][10]/length\n",
    "            text_geo_std = results[model][approach][key][\"mean\"][11]/length\n",
    "            text_harm_std = results[model][approach][key][\"mean\"][12]/length\n",
    "\n",
    "            plt.plot(x, main_arith, \"s-\", color=\"blue\", label=\"Arithmetic\", )\n",
    "            plt.fill_between(x, main_arith-main_arith_std, main_arith+main_arith_std, color=\"blue\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            plt.plot(x, main_geo, \"s-\", color=\"red\", label=\"Geometic\")\n",
    "            plt.fill_between(x, main_geo-main_geo_std, main_geo+main_geo_std, color=\"red\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            plt.plot(x, main_harm, \"s-\", color=\"green\", label=\"Harmonic\")\n",
    "            plt.fill_between(x, main_harm-main_harm_std, main_harm+main_harm_std, color=\"green\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            plt.plot(x, text_arith, \"o-\", color=\"blue\", label=\"Arithmetic (no context)\")\n",
    "            plt.fill_between(x, text_arith-text_arith_std, text_arith+text_arith_std, color=\"blue\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            plt.plot(x, text_geo, \"o-\", color=\"red\", label=\"Geometic (no context)\")\n",
    "            plt.fill_between(x, text_geo-text_geo_std, text_geo+text_geo_std, color=\"red\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            plt.plot(x, text_harm, \"o-\", color=\"green\", label=\"Harmonic (no context)\")\n",
    "            plt.fill_between(x, text_harm-text_harm_std, text_harm+text_harm_std, color=\"green\", edgecolor=\"none\", alpha=0.1)\n",
    "\n",
    "            \n",
    "            # plt.errorbar(x, main_arith, main_arith_std, color=\"blue\", label=\"Arithmetic\")\n",
    "            # plt.errorbar(x, main_geo, main_geo_std, color=\"red\", label=\"Geometric\")\n",
    "            # plt.errorbar(x, main_harm, main_harm_std, color=\"green\", label=\"Harmonic\")\n",
    "\n",
    "            # plt.errorbar(x, text_arith, text_arith_std, color=\"blue\", marker=\"o\", label=\"Arithmetic (w/o domain)\")\n",
    "            # plt.errorbar(x, text_geo, text_geo_std, color=\"red\", marker=\"o\", label=\"Geometric (w/o domain)\")\n",
    "            # plt.errorbar(x, text_harm, text_harm_std, color=\"green\", marker=\"o\", label=\"Harmonic (w/o domain)\")\n",
    "            plt.title(model)\n",
    "            plt.legend(loc=\"best\")\n",
    "            plt.savefig(save_figfile)\n",
    "            plt.clf()\n",
    "            # plt.show()\n",
    "        # input()\n",
    "    # break\n",
    "            # plt.clf()\n",
    "\n",
    "            if \"gpt-j\" in model:\n",
    "                for x, y, ye in zip(range(10), main_arith, main_arith_std):\n",
    "                    print(x, y, ye)\n",
    "                print()\n",
    "                for x, y, ye in zip(range(10), text_arith, text_arith_std):\n",
    "                    print(x, y, ye)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task direct-simple direct-context direct-instruct channel\n",
      "SST2  & 69.5\\std{1.2} & 65.9\\std{0.9} & 43.6\\std{1.0} & 74.5\\std{1.2} & 75.7\\std{1.3} & 72.3\\std{0.7} & 80.0\\std{1.0} & 87.1\\std{0.6} & \\textbf{91.7}\\std{0.2}\\\\\n",
      "SST5  & 18.6\\std{0.7} & 24.2\\std{0.9} & 25.1\\std{0.2} & 26.2\\std{0.7} & 29.8\\std{0.6} & 35.6\\std{0.2} & 34.8\\std{0.8} & 36.0\\std{1.2} & \\textbf{40.9}\\std{0.5}\\\\\n",
      "Yelp2  & 68.1\\std{1.0} & 64.2\\std{1.1} & 76.7\\std{0.3} & 70.5\\std{0.5} & 70.2\\std{0.6} & 75.9\\std{0.5} & 76.1\\std{0.8} & 85.4\\std{0.7} & \\textbf{89.9}\\std{0.1}\\\\\n",
      "Yelp5  & 24.0\\std{1.1} & 26.2\\std{0.7} & 25.6\\std{0.3} & 30.5\\std{1.1} & 28.5\\std{1.4} & 32.0\\std{0.3} & 35.5\\std{0.8} & 38.0\\std{0.7} & \\textbf{42.0}\\std{0.3}\\\\\n",
      "Amazon2  & 61.0\\std{1.7} & 61.0\\std{1.7} & 58.2\\std{0.5} & 72.7\\std{1.2} & 72.7\\std{1.2} & \\textbf{78.7}\\std{0.4} & 68.4\\std{1.1} & 68.4\\std{1.1} & 71.3\\std{0.4}\\\\\n",
      "MR  & 67.7\\std{0.9} & 63.3\\std{1.0} & 51.3\\std{0.5} & 72.3\\std{1.0} & 70.6\\std{1.2} & 74.6\\std{0.5} & 76.0\\std{0.9} & 84.2\\std{0.6} & \\textbf{87.0}\\std{0.2}\\\\\n",
      "CR  & 57.3\\std{2.7} & 57.1\\std{2.8} & 51.8\\std{1.1} & 60.3\\std{2.1} & 66.4\\std{2.9} & 66.7\\std{0.9} & 72.9\\std{1.7} & 83.8\\std{1.5} & \\textbf{87.0}\\std{0.2}\\\\\n",
      "Tweet3  & 36.0\\std{0.2} & 35.5\\std{0.4} & 31.9\\std{0.1} & 39.4\\std{0.4} & 39.7\\std{0.5} & \\textbf{43.0}\\std{0.1} & 42.2\\std{0.3} & 42.2\\std{0.3} & 41.1\\std{0.1}\\\\\n",
      "FP  & 36.6\\std{2.3} & 32.3\\std{2.0} & 25.2\\std{0.5} & 38.7\\std{1.9} & 39.8\\std{3.2} & 47.8\\std{1.4} & 44.7\\std{1.8} & 48.2\\std{2.4} & \\textbf{52.9}\\std{1.1}\\\\\n",
      "PS  & 38.0\\std{5.1} & 32.9\\std{4.9} & 30.3\\std{1.6} & 35.8\\std{3.4} & 33.8\\std{4.1} & 21.3\\std{1.3} & 39.2\\std{3.3} & 38.4\\std{4.2} & \\textbf{42.4}\\std{1.2}\\\\\n",
      "AGNews  & 34.8\\std{0.5} & 34.8\\std{0.5} & 37.9\\std{0.2} & 54.6\\std{0.5} & 54.6\\std{0.5} & 72.0\\std{0.2} & 64.9\\std{0.4} & 64.9\\std{0.4} & \\textbf{77.0}\\std{0.1}\\\\\n",
      "DBPedia  & 42.5\\std{0.5} & 39.4\\std{0.7} & 32.8\\std{0.4} & 61.7\\std{0.5} & 66.6\\std{0.8} & 78.9\\std{0.1} & 71.7\\std{0.5} & 71.7\\std{0.5} & \\textbf{80.1}\\std{0.2}\\\\\n",
      "HS18  & 17.4\\std{0.5} & 14.7\\std{0.7} & 10.1\\std{0.0} & 37.2\\std{1.0} & 38.7\\std{0.9} & 29.9\\std{0.3} & 50.2\\std{0.7} & 55.8\\std{0.9} & \\textbf{62.6}\\std{0.3}\\\\\n",
      "Tweet  & 30.7\\std{0.4} & 30.7\\std{0.4} & 29.7\\std{0.0} & 42.9\\std{0.3} & 42.9\\std{0.3} & 37.7\\std{0.2} & \\textbf{48.1}\\std{0.6} & \\textbf{48.1}\\std{0.6} & 42.7\\std{0.1}\\\\\n",
      "Ethos (NO)  & 50.8\\std{3.0} & 50.8\\std{3.0} & \\textbf{63.2}\\std{3.0} & 54.9\\std{2.1} & 54.9\\std{2.1} & 55.7\\std{1.5} & 50.4\\std{3.0} & 50.4\\std{3.0} & 56.3\\std{0.8}\\\\\n",
      "Ethos (SO)  & 33.8\\std{4.7} & 33.8\\std{4.7} & 20.4\\std{0.7} & 52.5\\std{5.4} & 52.5\\std{5.4} & 55.3\\std{1.7} & 52.7\\std{2.8} & 52.7\\std{2.8} & \\textbf{62.3}\\std{1.6}\\\\\n",
      "Ethos (Race)  & 27.4\\std{3.8} & 27.4\\std{3.8} & 15.5\\std{0.0} & 54.5\\std{4.3} & 54.5\\std{4.3} & 50.9\\std{1.9} & 56.1\\std{3.1} & 56.1\\std{3.1} & \\textbf{60.5}\\std{1.3}\\\\\n",
      "Ethos (Religion)  & 48.2\\std{3.9} & 48.2\\std{3.9} & 42.5\\std{1.8} & 62.3\\std{2.8} & 62.3\\std{2.8} & 62.8\\std{1.3} & 62.9\\std{3.7} & 62.9\\std{3.7} & \\textbf{70.1}\\std{0.9}\\\\\n",
      "Emotions  & 24.9\\std{0.4} & 23.5\\std{0.6} & 29.0\\std{0.3} & 31.4\\std{1.0} & 31.8\\std{1.1} & \\textbf{37.8}\\std{0.2} & 30.3\\std{0.8} & 30.3\\std{0.8} & 32.7\\std{0.3}\\\\\n"
     ]
    }
   ],
   "source": [
    "create_results_table(\"EleutherAI/gpt-j-6b\", results, \"f1\")\n",
    "# results[\"EleutherAI/gpt-j-6b\"]['direct-simple']['direct']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# \"direct-context\", \"direct-instruct\", \n",
    "print(len(tasks))\n",
    "def create_results_table(model, results, metric=\"accuracy\"):\n",
    "    print(\"task\", \"direct-simple\", \"direct-context\", \"direct-instruct\", \"channel\")\n",
    "    for task, task_name in zip(tasks, task_names):\n",
    "        print(f\"{task_name} \", end=\"\")\n",
    "        items = []\n",
    "        for approach in [\"direct-simple\", \"channel-simple\"]:\n",
    "            key = task\n",
    "            if metric == \"f1\":\n",
    "                key += \"_f1\"\n",
    "            try:\n",
    "                if \"channel\" in approach:\n",
    "                    result_array = [results[model][approach]['channel'][key]]\n",
    "                else:\n",
    "                    result_array = [results[model][approach]['direct'][key], results[model][approach]['direct++'][key]]\n",
    "                \n",
    "                for result in result_array:\n",
    "                    # if metric == \"accuracy\":\n",
    "                    # items = result[:7]\n",
    "\n",
    "                    x = result[0]\n",
    "\n",
    "                    arithmean = result[1]\n",
    "                    arithstd = result[4]\n",
    "\n",
    "                    geomean = result[2]\n",
    "                    geostd = result[5]\n",
    "\n",
    "                    harmmean = result[3]\n",
    "                    harmstd = result[6]\n",
    "\n",
    "                    nocontext_arithmean = result[7]\n",
    "                    nocontext_arithstd = result[10]\n",
    "\n",
    "                    nocontext_geomean = result[8]\n",
    "                    nocontext_geostd = result[11]\n",
    "\n",
    "                    nocontext_harmmean = result[9]\n",
    "                    nocontext_harmstd = result[12]\n",
    "                    \n",
    "                    items += [(nocontext_arithmean[0], nocontext_arithstd[0]), (arithmean[0], arithstd[0]), (arithmean[-1], arithstd[-1])]\n",
    "\n",
    "                    # print(f\"& {nocontext_arithmean[0]*100:.1f}$_{{({nocontext_arithstd[0]*100:.1f})}}$ & {arithmean[0]*100:.1f}$_{{({arithstd[0]*100:.1f})}}$ & {arithmean[-1]*100:.1f}$_{{({arithstd[-1]*100:.1f})}}$\", end=\"\")\n",
    "                    # print(f\"& {nocontext_geomean[0]*100:.1f}$_{{({nocontext_geostd[0]*100:.1f})}}$ & {geomean[0]*100:.1f}$_{{({geostd[0]*100:.1f})}}$ & {geomean[-1]*100:.1f}$_{{({geostd[-1]*100:.1f})}}$\", end=\"\")\n",
    "                    # print(f\"& {nocontext_harmmean[0]*100:.1f}$_{{({nocontext_harmstd[0]*100:.1f})}}$ & {harmmean[0]*100:.1f}$_{{({harmstd[0]*100:.1f})}}$ & {harmmean[-1]*100:.1f}$_{{({harmstd[-1]*100:.1f})}}$\", end=\"\")\n",
    "            except:\n",
    "                if \"channel\" in approach:\n",
    "                    items += [(0,0), (0,0), (0,0)]\n",
    "                    # print(f\"& & &\", end=0)\n",
    "                else:\n",
    "                    items += [(0,0), (0,0), (0,0), (0,0), (0,0), (0,0)]\n",
    "                    # print(f\"& & & & & & \", end=\"\")\n",
    "        \n",
    "        # print(len(items))\n",
    "        max_mean = max(items, key=lambda x: x[0])\n",
    "        for item in items:\n",
    "            if item[0] == max_mean[0]:\n",
    "                print(f\" & \\\\textbf{{{item[0]*100:.1f}}}\\std{{{item[1]*100:0.1f}}}\", end=\"\")\n",
    "            else:\n",
    "                print(f\" & {item[0]*100:.1f}\\std{{{item[1]*100:0.1f}}}\", end=\"\")\n",
    "            \n",
    "        print(\"\\\\\\\\\")\n",
    "\n",
    "        \n",
    "                # else:\n",
    "                    # items = result[:1] + result[7:]\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
